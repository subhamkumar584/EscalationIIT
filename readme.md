# Causal Analysis and Interactive Reasoning over Conversational Data

## 1. Project Overview
This project implements an **endâ€‘toâ€‘end system** to explain **why outcome events**
(such as escalations) occur in customerâ€“agent conversations.

Given a **naturalâ€‘language analytical query**, the system identifies
**dialogueâ€‘level causal factors**, retrieves **supporting conversational evidence**,
and generates **interpretable explanations**. The system also supports
**multiâ€‘turn followâ€‘up queries** by maintaining explicit session context.

---

## 2. Problem Statement

Largeâ€‘scale customer support systems generate multiâ€‘turn conversations between
customers and agents. Some conversations result in important outcome events such
as escalations, complaints, or refunds. While these events are logged, existing
systems do not explain the **conversational causes** behind them.

The objective is to design a system that:
- Identifies **dialogueâ€‘level causal factors**
- Grounds explanations in **concrete conversational evidence**
- Supports **interactive, multiâ€‘turn reasoning**
- Produces **interpretable and reproducible outputs**

### Task 1: Queryâ€‘Driven Causal Explanation
Given a single naturalâ€‘language query, the system must analyze relevant
conversations, identify causal factors, retrieve supporting dialogue evidence,
and generate a structured explanation.

### Task 2: Multiâ€‘Turn Contextâ€‘Aware Reasoning
The system must retain context across followâ€‘up queries and ensure consistency
in causal reasoning and evidence usage across multiple interactions.

---

## 3. Why This System Is Better Than Others

Compared to traditional systems, this approach:

- Goes beyond simple **event detection** to provide **causal explanations**
- Grounds explanations in **explicit conversational evidence**
- Supports **multiâ€‘turn interactive reasoning**
- Uses **interpretable ruleâ€‘based logic** instead of blackâ€‘box models
- Is **fully reproducible** and **CPUâ€‘only**

This makes the system more **transparent, trustworthy, and evaluatorâ€‘friendly**.

---

## 4. Technologies Used

| Technology | Purpose |
|----------|--------|
| Python | Core system implementation |
| Pandas | Data handling and CSV generation |
| NumPy | Numerical and vector operations |
| Sentenceâ€‘Transformers | Semantic text embeddings |
| FAISS (CPU) | Vector similarity search |
| Ruleâ€‘Based Causal Logic | Interpretable reasoning |
| Context Manager | Multiâ€‘turn query handling |

---

## 5. Hardware Requirements
- CPUâ€‘only environment  
- No GPU required  
- Sufficient RAM to store conversation embeddings  

---

## 6. Software Requirements
- Python **3.8 or higher**
- All dependencies listed in `requirements.txt`

```bash 
pip install -r requirements.txt
```
## 7. System Workflow
<ol type="I">
  <li>User submits a naturalâ€‘language analytical query</li>
  <li>Query intent is interpreted (new or followâ€‘up)</li>
  <li>Previous session context is retrieved if required</li>
  <li>Causal reasoning is applied over conversations</li>
  <li>Supporting dialogue evidence is retrieved</li>
    <li>Structured explanation is generated</li>
  <li> Evaluation metrics are computed</li>
  <li>Final output is returned and context is updatedFinal output is returned and context is updated</li>
   
</ol>

## 8. Sample Input and Output
### Input:The system accepts a naturalâ€‘language analytical question from the user:
<img width="515" height="139" alt="Screenshot 2026-02-07 065424" src="https://github.com/user-attachments/assets/23e86fb7-2516-4193-b2db-8ad8a2de318c" />
This query asks for the cause behind an escalation outcome observed in customerâ€“agent conversations.

### Output:After processing the query, the system generates a structured causal explanation consisting of:
Detected Outcome: ESCALATION
Confidence Level: HIGH
Causal Factor Identified:
Threat of legal action by the customer
Supporting Evidence:
Exact dialogue turns from conversations where customers explicitly mention legal action
Final Summary:
A concise explanation linking repeated unresolved interactions and legal threats to the escalation
Evaluation Metrics:
IDRecall (Evidence Accuracy)
Faithfulness (Hallucination Control)
Relevancy (Conversational Coherence)
### ğŸ–¼ Sample Output Screenshot
The screenshot below shows the actual terminal output generated by the system for the above input query:
<img width="1227" height="306" alt="Screenshot 2026-02-07 065539" src="https://github.com/user-attachments/assets/40d8052d-a10c-4215-b905-cb239d374408" />

## 9. Evaluation Metrics

| Metric       | Description |
|-------------|-------------|
| **IDRecall** | Accuracy of retrieved conversational evidence |
| **Faithfulness** | Ensures explanations are grounded in retrieved context (no hallucinations) |
| **Relevancy** | Alignment with user intent, especially in multiâ€‘turn queries |

## 10. Folder Structure

```
EsclationIIT/
â”œâ”€â”€ dataset/                     # Input conversational datasets
â”œâ”€â”€ models/                      # Saved embeddings / intermediate models
â”œâ”€â”€ outputs/                     # Generated explanations and logs
â”œâ”€â”€ src/                         # Core system implementation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py                   # Command-line interface (entry point)
â”‚   â”œâ”€â”€ batch_runner.py          # Batch evaluation runner (Task 1 & 2)
â”‚   â”œâ”€â”€ config.py                # Central configuration settings
â”‚   â”œâ”€â”€ data_loader.py           # Loads and preprocesses conversation data
â”‚   â”œâ”€â”€ retriever.py             # FAISS-based evidence retrieval
â”‚   â”œâ”€â”€ causal_patterns.py       # Rule-based causal pattern definitions
â”‚   â”œâ”€â”€ causal_aggregator.py     # Aggregates dialogue-level causal signals
â”‚   â”œâ”€â”€ reasoning_engine.py      # Core causal reasoning logic
â”‚   â”œâ”€â”€ reasoning_router.py      # Routes queries to correct reasoning path
â”‚   â”œâ”€â”€ query_interpreter.py     # Interprets user intent (new / follow-up)
â”‚   â”œâ”€â”€ context_store.py         # Stores session-level context
â”‚   â”œâ”€â”€ context_manager.py       # Manages multi-turn conversational context
â”‚   â”œâ”€â”€ session_controller.py    # Controls interaction flow
â”‚   â”œâ”€â”€ response_generator.py    # Generates structured explanations
â”‚   â”œâ”€â”€ final_explainer.py       # Produces final user-facing output
â”‚   â””â”€â”€ outcome_validator.py     # Validates outcomes against constraints
â”œâ”€â”€ evaluation_results.csv       # Final evaluation outputs (used for judging)
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # Project documentation
â””â”€â”€ ML_HACKATHON_PRAVAAH.pdf     # Technical report

```

## 11. How to Run the System
### Interactive Mode
```python src/cli.py```
### Batch Evaluation Mode (Used for Evaluation)
```python src/batch_runner.py```
This generates a CSV file containing:

- Query ID

- Query

- Query Category

- System Output

- Remarks

âš ï¸ This CSV file is used directly for evaluation.

## 12. Conclusion
This project demonstrates how causal reasoning, semantic retrieval, and
explicit context management can be combined to move beyond simple event
detection and enable interactive, evidenceâ€‘grounded causal analysis over
conversational data. The system is interpretable, reproducible, and wellâ€‘suited
for largeâ€‘scale conversational analysis.

## Notes for Evaluators
- No external APIs are used

- No GPU or paid services required

- Fully reproducible on CPU

- Deterministic and interpretable outputs
